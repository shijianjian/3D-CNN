{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data comes from http://web.stanford.edu/~ericyi/project_page/part_annotation/index.html\n",
    "from pyntcloud import PyntCloud\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "if sys.platform == 'darwin':\n",
    "    data_path = os.getcwd() + \"/PartAnnotation\"\n",
    "else:\n",
    "    data_path = os.getcwd() + \"\\\\PartAnnotation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_data(data_path, max_file_num=None, folder_filter=(None, None)):\n",
    "    \"\"\"\n",
    "    Find file in each folder according to the 'data_path'.\n",
    "    \n",
    "    Giving the max number of files via `max_file_num`, it will read first `max_file_num` in each folder. Read all if there is no enough file inside.\n",
    "    \n",
    "    `folder_filter` is a tuple like (100, 2000) which indicates the number of files will between 100 and 2000.\n",
    "    \"\"\"\n",
    "    \n",
    "    min_th, max_th = folder_filter\n",
    "    if max_file_num is not None and folder_filter is not None:\n",
    "        if min_th is not None:\n",
    "            assert(max_file_num > min_th), \"`max_file_num` should be greater than `\" + min_th + \"` in \" + folder_filter\n",
    "        \n",
    "    data = []\n",
    "    label = []\n",
    "    for entry in os.scandir(data_path):\n",
    "        if entry.is_dir():\n",
    "            target_dir_path = os.path.join(data_path, entry.name, 'points')\n",
    "            path, dirs, files = os.walk(target_dir_path).__next__()\n",
    "            file_count = len(files)\n",
    "            if (min_th is None or file_count >= min_th) and (max_th is None or file_count <= max_th):\n",
    "                count = 0\n",
    "                for pts_data in os.scandir(target_dir_path):\n",
    "                    if (max_file_num is None) or (count < max_file_num):\n",
    "                        data.append(os.path.join(data_path, entry.name, 'points', pts_data.name))\n",
    "                        label.append(entry.name)\n",
    "                        count += 1\n",
    "                    else:\n",
    "                        break\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voxelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voxelize3D(pts, dim=[1,1,1]):\n",
    "    \"\"\"\n",
    "    pts: receives .pts cloud point data. 2D array, arbitary sized X,Y,Z pairs. (We will only take x,y,z into account for now)\n",
    "    dim: dimensioin of output voxelized data\n",
    "    \n",
    "    This function will locate the grid cube and calculate the density of each cube.\n",
    "    The output will be normalized values.\n",
    "    \"\"\"\n",
    "    assert(pts.shape[1]>=3), \"pts file should contain at least x,y,z coordinate\"\n",
    "    assert(len(dim)==3), \"Please provide 3-d grid size like [32,32,32]\"\n",
    "    \n",
    "    # move all the axis to positive area.\n",
    "    minimum_val = [pts[0][0], pts[0][1], pts[0][2]]\n",
    "\n",
    "    # find the smallest \n",
    "    for pair in pts:\n",
    "        if pair[0] < minimum_val[0]:\n",
    "            minimum_val[0] = pair[0]\n",
    "        if pair[1] < minimum_val[1]:\n",
    "            minimum_val[1] = pair[1]\n",
    "        if pair[2] < minimum_val[2]:\n",
    "            minimum_val[2] = pair[2]\n",
    "            \n",
    "    # move it to first quadrant \n",
    "    rectified_pts = np.empty(pts.shape)\n",
    "    for index, pair in enumerate(pts):\n",
    "        point = np.zeros(3)\n",
    "        point[0] = pair[0] - minimum_val[0]\n",
    "        point[1] = pair[1] - minimum_val[1]\n",
    "        point[2] = pair[2] - minimum_val[2]\n",
    "        rectified_pts[index] = point\n",
    "    \n",
    "    # biggest value in each axis \n",
    "    maximum_val = pts[0][0]\n",
    "    \n",
    "    for pair in rectified_pts:\n",
    "        for val in pair:\n",
    "            if val > maximum_val:\n",
    "                maximum_val = val\n",
    "     \n",
    "    # normalize all the axises to (0,1)\n",
    "    normalized_pts = rectified_pts/maximum_val\n",
    "    \n",
    "    x_grid_length = 1/dim[0]\n",
    "    y_grid_length = 1/dim[1]\n",
    "    z_grid_length = 1/dim[2]\n",
    "    \n",
    "    output = np.zeros((dim[0],dim[1],dim[2]))\n",
    "    \n",
    "    epsilon = 0.000000000001 # we will have at least a 1.0 value which will exceed the index of grid\n",
    "    # we can use a relativly small value to escape that to fit our data\n",
    "    \n",
    "    max_volume_size = 0\n",
    "    \n",
    "    for pair in normalized_pts:\n",
    "        x_loc = int(pair[0]/(x_grid_length + epsilon))\n",
    "        y_loc = int(pair[1]/(y_grid_length + epsilon))\n",
    "        z_loc = int(pair[2]/(z_grid_length + epsilon))\n",
    "        if output[x_loc, y_loc, z_loc] is None:\n",
    "            output[x_loc, y_loc, z_loc] = 1\n",
    "        else:\n",
    "            output[x_loc, y_loc, z_loc] += 1\n",
    "        \n",
    "        if output[x_loc, y_loc, z_loc] > max_volume_size:\n",
    "            max_volume_size = output[x_loc, y_loc, z_loc]\n",
    "    \n",
    "    output = output/max_volume_size    \n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = find_data(data_path, folder_filter=(10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297 297\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_point_cloud = PyntCloud.from_file(data[30], sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(xyz, filename='xyz'):\n",
    "    import os\n",
    "    file = open(os.path.join(os.getcwd(), filename + \".pts\"), \"w\") \n",
    "    \n",
    "    for point in xyz:\n",
    "        st = \"\"\n",
    "        for item in point:\n",
    "            st += str(item) + \" \"\n",
    "        file.write(st.strip() + \"\\n\")\n",
    "\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path, max_file_num=None, dim=[32,32,32]):\n",
    "    \"\"\"\n",
    "    Output original xyz based points and voxelized data.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    target_dir_path = os.path.join(data_path, 'points')\n",
    "    path, dirs, files = os.walk(target_dir_path).__next__()\n",
    "    file_count = len(files)\n",
    "    \n",
    "    count = 0\n",
    "    for pts_data in os.scandir(target_dir_path):\n",
    "        if (max_file_num is None) or (count < max_file_num):\n",
    "            _path = os.path.join(data_path, 'points', pts_data.name)\n",
    "            pts = PyntCloud.from_file(_path, sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])\n",
    "            \n",
    "            _vox = voxelize3D(pts.xyz, dim=dim)\n",
    "            vox_chan = np.array(_vox).reshape(_vox.shape + (1,))\n",
    "            data.append(vox_chan)\n",
    "            count += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "                \n",
    "    return np.asarray(data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process:   100% \n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def write_big_files_to_h5(data_path, folder_filter=(None, None), dim=[32,32,32]):\n",
    "    \n",
    "    data, label = find_data(data_path, folder_filter=folder_filter)\n",
    "    \n",
    "    _shuffled_data_raw, _shuffled_label_raw = data_shuffling(data, label)\n",
    "    \n",
    "    _shuffled_data = data_reshape(_shuffled_data_raw)\n",
    "    _shuffled_label, _label_ref = data_onehot_encode(_shuffled_label_raw)\n",
    "\n",
    "    # Create hdf5\n",
    "    hdf5_path = os.path.join(data_path, 'small_shuffled_sets.h5')\n",
    "    hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "\n",
    "    hdf5_file.create_dataset(\"voxels\", data=_shuffled_data[:])\n",
    "    hdf5_file.create_dataset(\"labels\", data=_shuffled_label[:])\n",
    "    hdf5_file.create_dataset('label_ref', data=np.array(_label_ref).astype('|S9')) # ASCII\n",
    "            \n",
    "            \n",
    "write_big_files_to_h5(data_path, folder_filter=(None, 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 32, 32, 32, 1) (297, 4)\n"
     ]
    }
   ],
   "source": [
    "h5 = h5py.File(os.path.join(data_path, 'big_shuffled_sets.h5'), mode='r')\n",
    "d = h5.get(\"voxels\")\n",
    "ll = h5.get('labels')\n",
    "l = h5.get(\"label_ref\")\n",
    "print(d.shape, ll[:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output with binary cells instead of density\n",
    "import h5py\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def density_converter(data_path, file_name):\n",
    "    h5 = h5py.File(data_path, mode='r')\n",
    "    vox = h5.get(\"voxels\")\n",
    "    _data = []\n",
    "    for index, value in enumerate(vox):\n",
    "        idx = value > 0\n",
    "        val = np.ones(value.shape) * idx\n",
    "        _data.append(val)\n",
    "        print(\"Process:\" + str('{0:.2f}'.format(index/len(vox))), end='\\r')\n",
    "    \n",
    "    _data = np.asarray(_data, dtype=np.float32)\n",
    "    hdf5_path = os.path.join(os.getcwd(), file_name)\n",
    "    hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "\n",
    "    hdf5_file.create_dataset(\"voxels\", data=_data[:])\n",
    "    hdf5_file.create_dataset(\"labels\", data=h5.get(\"labels\"))\n",
    "    hdf5_file.create_dataset('label_ref', data=h5.get(\"label_ref\")) # ASCII\n",
    "        \n",
    "# density_converter(os.path.join(os.getcwd(), 'h5dataset', 'big_shuffled_sets.h5'), \"test.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), 'test.h5')\n",
    "h5 = h5py.File(path, mode='r')\n",
    "_d = h5.get(\"voxels\")\n",
    "plot_voxelgrid(_d[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_each_folder_to_h5(data_path, dim=[32,32,32]):\n",
    "    for entry in os.scandir(data_path):\n",
    "        if entry.is_dir():\n",
    "            target_dir_path = os.path.join(data_path, entry.name)\n",
    "            data = get_data(target_dir_path, dim=dim)\n",
    "            \n",
    "            labels=np.empty(len(data), dtype='<U9'); # UTF-8\n",
    "            labels.fill(entry.name)\n",
    "\n",
    "            # Create hdf5\n",
    "            hdf5_path = os.path.join(data_path, entry.name + '.h5')\n",
    "            hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "\n",
    "            hdf5_file.create_dataset(\"voxels\", data=data[:])\n",
    "            hdf5_file.create_dataset('label_ref', data=labels.astype('|S9')) # ASCII\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = h5py.File(os.path.join(os.getcwd(), 'h5dataset', 'table.h5'), mode='r')\n",
    "d = h5.get(\"points\")\n",
    "l = h5.get(\"label_ref\")\n",
    "print(d.shape, l[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ./voxel_grid_plot.py\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import IFrame\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def plot_voxelgrid(voxelgrid,\n",
    "                   output_name=None,\n",
    "                   cmap=\"Oranges\",\n",
    "                   axis=True,\n",
    "                   width=800,\n",
    "                   height=600):\n",
    "\n",
    "    scaled_shape = voxelgrid.shape\n",
    "\n",
    "    vector = voxelgrid\n",
    "    points = np.argwhere(vector) * scaled_shape\n",
    "\n",
    "    s_m = plt.cm.ScalarMappable(cmap=cmap)\n",
    "    rgb = s_m.to_rgba(vector.reshape(-1)[vector.reshape(-1) > 0])\n",
    "\n",
    "    camera_position = points.max(0) + abs(points.max(0))\n",
    "\n",
    "    look = points.mean(0)\n",
    "\n",
    "    if axis:\n",
    "        axis_size = points.ptp() * 1.5\n",
    "    else:\n",
    "        axis_size = 0\n",
    "\n",
    "    placeholders = {}\n",
    "\n",
    "    placeholders[\"POINTS_X_PLACEHOLDER\"] = points[:, 0].tolist()\n",
    "    placeholders[\"POINTS_Y_PLACEHOLDER\"] = points[:, 1].tolist()\n",
    "    placeholders[\"POINTS_Z_PLACEHOLDER\"] = points[:, 2].tolist()\n",
    "\n",
    "    placeholders[\"R_PLACEHOLDER\"] = rgb[:, 0].tolist()\n",
    "    placeholders[\"G_PLACEHOLDER\"] = rgb[:, 1].tolist()\n",
    "    placeholders[\"B_PLACEHOLDER\"] = rgb[:, 2].tolist()\n",
    "\n",
    "    placeholders[\"S_x_PLACEHOLDER\"] = scaled_shape[0]\n",
    "    placeholders[\"S_y_PLACEHOLDER\"] = scaled_shape[1]\n",
    "    placeholders[\"S_z_PLACEHOLDER\"] = scaled_shape[2]\n",
    "\n",
    "    placeholders[\"CAMERA_X_PLACEHOLDER\"] = camera_position[0]\n",
    "    placeholders[\"CAMERA_Y_PLACEHOLDER\"] = camera_position[1]\n",
    "    placeholders[\"CAMERA_Z_PLACEHOLDER\"] = camera_position[2]\n",
    "\n",
    "    placeholders[\"LOOK_X_PLACEHOLDER\"] = look[0]\n",
    "    placeholders[\"LOOK_Y_PLACEHOLDER\"] = look[1]\n",
    "    placeholders[\"LOOK_Z_PLACEHOLDER\"] = look[2]\n",
    "\n",
    "    placeholders[\"AXIS_SIZE_PLACEHOLDER\"] = axis_size\n",
    "\n",
    "    placeholders[\"N_VOXELS_PLACEHOLDER\"] = sum(vector.reshape(-1) > 0)\n",
    "\n",
    "    if output_name is None:\n",
    "        output_name = \"plotVG.html\"\n",
    "\n",
    "    BASE_PATH = os.getcwd()\n",
    "    src = \"{}/{}\".format(BASE_PATH, \"voxelgrid.html\")\n",
    "    dst = \"{}/{}\".format(os.getcwd(), output_name)\n",
    "\n",
    "    with open(src, \"r\") as inp, open(dst, \"w\") as out:\n",
    "        for line in inp:\n",
    "            for key, val in placeholders.items():\n",
    "                if key in line:\n",
    "                    line = line.replace(key, str(val))\n",
    "            out.write(line)\n",
    "\n",
    "    return IFrame(output_name, width=width, height=height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rotate(pts, axis=0, angle_degree=30):\n",
    "    \"\"\"\n",
    "    Rotate the pts point cloud by a specific angle.\n",
    "    \n",
    "    axis = 0 : rotate around x-axis\n",
    "    axis = 1 : rotate around y-axis\n",
    "    axis = 2 : rotate around z-axis\n",
    "    \n",
    "    angle_degree : how much degree you want to rotate the point cloud.\n",
    "    \n",
    "    Algorithm comes in: https://uk.mathworks.com/matlabcentral/answers/123763-how-to-rotate-entire-3d-data-with-x-y-z-values-along-a-particular-axis-say-x-axis\n",
    "    \"\"\"\n",
    "    if axis == 0: \n",
    "        return rotate_by_x(pts, angle_degree)\n",
    "    if axis == 1: \n",
    "        return rotate_by_y(pts, angle_degree)\n",
    "    if axis == 2: \n",
    "        return rotate_by_z(pts, angle_degree)\n",
    "    \n",
    "def rotate_by_x(pts, angle_degree=30):\n",
    "    import numpy as np\n",
    "    degree = np.deg2rad(angle_degree)\n",
    "    res = np.empty(pts.shape)\n",
    "    for index, point in enumerate(pts):\n",
    "        new_point = np.zeros(3)\n",
    "        new_point[0] = point[0] # x\n",
    "        new_point[1] = point[1]*np.cos(degree) - point[2]*np.sin(degree) # y\n",
    "        new_point[2] = point[1]*np.sin(degree) + point[2]*np.cos(degree) # z\n",
    "        res[index] = new_point\n",
    "        \n",
    "    return res\n",
    "\n",
    "    \n",
    "def rotate_by_y(pts, angle_degree=30):\n",
    "    import numpy as np\n",
    "    degree = np.deg2rad(angle_degree)\n",
    "    res = np.empty(pts.shape)\n",
    "    for index, point in enumerate(pts):\n",
    "        new_point = np.zeros(3)\n",
    "        new_point[0] = point[0]*np.cos(degree) + point[2]*np.sin(degree) # x\n",
    "        new_point[1] = point[1] # y\n",
    "        new_point[2] = point[2]*np.cos(degree) - point[0]*np.sin(degree) # z\n",
    "        res[index] = new_point\n",
    "        \n",
    "    return res\n",
    "\n",
    "    \n",
    "def rotate_by_z(pts, angle_degree=30):\n",
    "    import numpy as np\n",
    "    degree = np.deg2rad(angle_degree)\n",
    "    res = np.empty(pts.shape)\n",
    "    for index, point in enumerate(pts):\n",
    "        new_point = np.zeros(3)\n",
    "        new_point[0] = point[0]*np.cos(degree) - point[1]*np.sin(degree) # x\n",
    "        new_point[1] = point[0]*np.sin(degree) + point[1]*np.cos(degree) # y\n",
    "        new_point[2] = point[2] # z\n",
    "        res[index] = new_point\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_point_cloud = rotate(my_point_cloud.xyz, angle_degree=180)\n",
    "write_to_file(rotated_point_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x115b199b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated_point_cloud_file = PyntCloud.from_file(os.path.join(os.getcwd(), \"xyz.pts\"), sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])\n",
    "rotated_point_cloud_file.plot(point_size=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squeeze_pts(pts, axis=0, percentage=10):\n",
    "    if axis==0:\n",
    "        return squeeze_by_x(pts, percentage)\n",
    "    if axis==1:\n",
    "        return squeeze_by_y(pts, percentage)\n",
    "    if axis==2:\n",
    "        return squeeze_by_z(pts, percentage)\n",
    "    \n",
    "def squeeze_by_x(pts, percentage):\n",
    "    \n",
    "    v = (100-percentage)/100\n",
    "    output = np.empty(pts.shape)\n",
    "    \n",
    "    assert(v>=0 and v<=1), \"Percentage should between 0 and 100\"\n",
    "    \n",
    "    for index, point in enumerate(pts):\n",
    "        output[index] = point\n",
    "        output[index][0] = output[index][0]*v\n",
    "        \n",
    "    return output\n",
    "    \n",
    "def squeeze_by_y(pts, percentage):\n",
    "    \n",
    "    v = (100-percentage)/100\n",
    "    output = np.empty(pts.shape)\n",
    "    \n",
    "    assert(v>=0 and v<=1), \"Percentage should between 0 and 100\"\n",
    "    \n",
    "    for index, point in enumerate(pts):\n",
    "        output[index] = point\n",
    "        output[index][1] = output[index][1]*v\n",
    "        \n",
    "    return output\n",
    "\n",
    "    \n",
    "def squeeze_by_z(pts, percentage):\n",
    "    \n",
    "    v = (100-percentage)/100\n",
    "    output = np.empty(pts.shape)\n",
    "    \n",
    "    assert(v>=0 and v<=1), \"Percentage should between 0 and 100\"\n",
    "    \n",
    "    for index, point in enumerate(pts):\n",
    "        output[index] = point\n",
    "        output[index][2] = output[index][2]*v\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "squeezed_pts = squeeze_pts(my_point_cloud.xyz, axis=1, percentage=30)\n",
    "write_to_file(squeezed_pts, filename=\"sq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x115b2c438>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rotated_point_cloud_file = PyntCloud.from_file(os.path.join(os.getcwd(), \"sq.pts\"), sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])\n",
    "rotated_point_cloud_file.plot(point_size=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(pts, noise_percentage=0.05):\n",
    "    \n",
    "    noise_size = int(noise_percentage*len(pts))\n",
    "    \n",
    "    max_x = min_x = pts[0][0]\n",
    "    max_y = min_y = pts[0][1]\n",
    "    max_z = min_z = pts[0][2]\n",
    "    \n",
    "    for point in pts:\n",
    "        if max_x < point[0]:\n",
    "            max_x = point[0]\n",
    "        if max_y < point[1]:\n",
    "            max_y = point[1]\n",
    "        if max_z < point[2]:\n",
    "            max_z = point[2]\n",
    "            \n",
    "        if min_x < point[0]:\n",
    "            min_x = point[0]\n",
    "        if min_y < point[1]:\n",
    "            min_y = point[1]\n",
    "        if min_y < point[2]:\n",
    "            min_y = point[2]\n",
    "            \n",
    "    import numpy as np\n",
    "    \n",
    "    noise_pts = np.empty((noise_size, 3))\n",
    "    noise_x = np.random.randn(noise_size)*(max_x - min_x)/2\n",
    "    noise_y = np.random.randn(noise_size)*(max_y - min_y)/2\n",
    "    noise_z = np.random.randn(noise_size)*(max_z - min_z)/2\n",
    "    \n",
    "    for i, _ in enumerate(range(noise_size)):\n",
    "        pos = np.random.randint(0,len(pts)-1)\n",
    "        noise_pts[i][0] = pts[pos][0] + noise_x[i]\n",
    "        noise_pts[i][1] = pts[pos][1] + noise_y[i]\n",
    "        noise_pts[i][2] = pts[pos][2] + noise_z[i]\n",
    "        \n",
    "    return np.concatenate((pts, noise_pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"500\"\n",
       "            src=\"pyntcloud_plot.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x10d9b7da0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_pts = add_noise(my_point_cloud.xyz)\n",
    "points_df = pd.DataFrame(noisy_pts, columns=[\"x\", \"y\", \"z\"])\n",
    "PyntCloud(points_df).plot(point_size=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reading & preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_cates(labels):\n",
    "    cates = []\n",
    "    for l in labels:\n",
    "        if l not in cates:\n",
    "            cates.append(l)\n",
    "    return cates\n",
    "\n",
    "def data_onehot_encode(labels):\n",
    "    \"\"\"\n",
    "    Recieves an array of labels.\n",
    "    \"\"\"\n",
    "    cates = label_cates(labels)\n",
    "    # one-hot\n",
    "    onehot = []\n",
    "    for l in labels:\n",
    "        x = np.zeros(len(cates))\n",
    "        x[cates.index(l)] = 1.0\n",
    "        onehot.append(x)\n",
    "    return onehot, cates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reshape(data, dim=[32,32,32]):\n",
    "    \"\"\"\n",
    "    Will read and voxelize the data\n",
    "    \"\"\"\n",
    "    x_reshaped = []\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if i % 20 == 0:\n",
    "            print(\"Process: \", str('{0:.2f}'.format(i/len(data))) + \"%\", end='\\r')\n",
    "        my_point_cloud = PyntCloud.from_file(data[i], sep=\" \", header=0, names=[\"x\",\"y\",\"z\"])\n",
    "        vox = voxelize3D(my_point_cloud.xyz, dim=dim)\n",
    "        vox_chan = np.array(vox).reshape(vox.shape + (1,))\n",
    "        x_reshaped.append(vox_chan)\n",
    "        \n",
    "    print(\"Process: \", \" 100% \")        \n",
    "    return x_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_swap(data, index_a, index_b):\n",
    "    temp = data[index_a]\n",
    "    data[index_a] = data[index_b]\n",
    "    data[index_b] = temp\n",
    "    return data\n",
    "\n",
    "def data_random_position(data):\n",
    "    import random\n",
    "    return random.randint(0,len(data)-1)\n",
    "\n",
    "def data_shuffling(data, label):\n",
    "    for i in range(len(data)):\n",
    "        target = data_random_position(data)\n",
    "        data = data_swap(data, i, target)\n",
    "        label = data_swap(label, i, target)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_data_raw, shuffled_label_raw = data_shuffling(data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process:   100% \n"
     ]
    }
   ],
   "source": [
    "shuffled_data = data_reshape(shuffled_data_raw)\n",
    "shuffled_label, label_ref = data_onehot_encode(shuffled_label_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32, 1)\n",
      "[ 0.  1.  0.  0.]\n",
      "4\n",
      "['rocket', 'cap', 'bag', 'earphone']\n"
     ]
    }
   ],
   "source": [
    "print(shuffled_data[100].shape)\n",
    "print(shuffled_label[100])\n",
    "print(len(shuffled_label[100]))\n",
    "print(label_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"label_ref\": shape (4,), type \"|S9\">"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# Create hdf5\n",
    "hdf5_path = os.path.join(os.getcwd(), 'small_dataset.h5')\n",
    "hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "\n",
    "hdf5_file.create_dataset(\"points\", data=shuffled_data[:])\n",
    "hdf5_file.create_dataset(\"labels\", data=shuffled_label[:])\n",
    "hdf5_file.create_dataset('label_ref', data=np.array(label_ref).astype('|S9'))\n",
    "# hdf5_file.create_dataset(\"label_ref\", data=label_ref[:], dtype=h5py.special_dtype(vlen=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 32)\n",
      "[b'rocket' b'cap' b'bag' b'earphone']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"plotVG.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1286ea5c0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5 = h5py.File(hdf5_path, mode='r')\n",
    "d = h5.get(\"points\")\n",
    "l = h5.get(\"labels\")\n",
    "re = h5.get(\"label_ref\")\n",
    "print(d[30][:,:,:,-1].shape)\n",
    "print(re[:])\n",
    "plot_voxelgrid(d[30][:,:,:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_point(point_cloud):\n",
    "    \n",
    "    ((x_min, x_max), (y_min, y_max), (z_min, z_max)) = find_ranges(point_cloud)\n",
    "    \n",
    "    biggest_value = np.max(np.asarray([x_max - x_min, y_max - y_min, z_max - z_min])) + 0.000000001\n",
    "    \n",
    "    normalized_points = []\n",
    "    for ind, coor in enumerate(point_cloud):\n",
    "        row = np.empty(len(coor))\n",
    "        row[0] = (coor[0] - x_min)/biggest_value\n",
    "        row[1] = (coor[1] - y_min)/biggest_value\n",
    "        row[2] = (coor[2] - z_min)/biggest_value\n",
    "        normalized_points.append(row)\n",
    "        \n",
    "    return np.asarray(normalized_points)\n",
    "\n",
    "def crop(point_cloud, ratio=((0, 1), (0, 1), (0, 1))):\n",
    "    \n",
    "    normed_point = norm_point(point_cloud)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for idx, row in enumerate(normed_point):\n",
    "        if row[0] > ratio[0][0] and row[0] < ratio[0][1]:\n",
    "            if row[1] > ratio[1][0] and row[1] < ratio[1][1]:\n",
    "                if row[2] > ratio[2][0] and row[2] < ratio[2][1]:\n",
    "                    res.append(row)\n",
    "                    \n",
    "    return np.asarray(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
